{
  "articleId": "summarize-article-by-llm-inference",
  "lang": "cn",
  "hash": "124691cabfe1f0e265a63a09e09670c92e20e069119d47c5038f85759636dd60",
  "summaries": [
    {
      "summaries": [
        "作者去年为博客添加AI摘要功能时，发现Azure AI语言服务处理中文效果欠佳，生成内容存在语句不通、格式错误等问题。近期改用Azure平台部署的DeepSeek R1模型后，通过优化提示词成功获得高质量摘要。尝试本地部署8B小模型时，效果不稳定且难以控制输出格式。对比发现大模型服务显著优于传统方案，但基于提示词的业务逻辑存在不确定性。文章揭示了AI应用中模型选择与工程实践的平衡难题，既肯定技术突破也表达对不可控性的隐忧。"
      ],
      "metadata": {
        "summarizer": "azure-ai",
        "model": "deepseek-r1"
      },
      "endTime": "2025-03-08T06:54:56.079Z",
      "startTime": "2025-03-08T06:54:37.549Z"
    },
    {
      "summaries": [
        "# 追寻可控的大模型调用：从LLM应用到业务逻辑建模\n\n在这次尝试中，我深刻体会到了使用大语言模型（LLM）开发功能的特殊性。传统的软件工程中，代码是对业务逻辑精确且确定性的表示，而LLM开发则呈现出一个完全不同的范式。\n\n## 1. LL M功能实现的玄学特性\n- **提示词为核心**：功能实现依赖于提示词设计。不同的提示词可能导致相同输入下不同的输出，甚至同一个提示词也可能生成多次不同的结果。\n- **不可预测性**：大模型对输入的解读和处理过程复杂且深层，输出往往具有不确定性，难以通过代码逻辑完全控制。\n\n## 2. 软件工程与LLM开发的异同\n- **传统软件逻辑**：业务逻辑明确、可控，模块划分清晰，测试可预测。\n- **LLM开发逻辑**：功能实现依赖于大模型的理解和生成能力，代码主要起到调用和结构化的作用。\n\n## 3. 处理不确定性与挑战\n- **适用场景选择**：在需要高度定制或精确控制的业务场景中，LLM可能不是最优选择。\n- **模型管理难题**：大模型的过大的计算需求和资源消耗，对硬件配置提出了较高要求。\n\n## 4. 对未来的思考\n尽管LLM在解决复杂问题方面展现出独特优势，但其不可控性仍然是一个主要挑战。未来需要在更精准的提示词设计、模型选择以及结果处理流程上寻找突破，才能真正将大语言模型应用于实际业务中。\n\n## 5. 结论\n这次体验让我认识到：在使用大语言模型时，不仅要理解其潜力和局限，更需要建立从需求到实现的全流程管理机制，以应对其不可预测性带来的挑战。"
      ],
      "metadata": {
        "summarizer": "ollama",
        "model": "deepseek-r1:8b"
      },
      "endTime": "2025-03-08T06:55:53.581Z",
      "startTime": "2025-03-08T06:54:56.080Z"
    },
    {
      "summaries": [
        "本文介绍了作者尝试使用Azure AI部署的DeepSeek R1模型，对自己博客上的文章进行总结，并得到了非常好的效果。本地跑一个8B版本的R1模型也取得了较好的效果，但存在不确定性，生成多时有可能出现不听话的情况。"
      ],
      "metadata": {
        "summarizer": "ollama",
        "model": "llamafamily/llama3-chinese-8b-instruct"
      },
      "endTime": "2025-03-08T06:56:03.053Z",
      "startTime": "2025-03-08T06:54:56.080Z"
    }
  ]
}